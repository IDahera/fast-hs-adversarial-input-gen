{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'global_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_layer, get_model\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataset_loader\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msuspiciousness\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ochiai, get_tarantula\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msuspiciousness\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collect_activations, compute_hit_spectrum, log_diagnostics\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensure_directory_exists, empty_gpu_cache\n",
      "File \u001b[0;32m~/repositories/sus-adv-gen/helper/suspiciousness.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglobal_variables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEVICE\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'global_variables'"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from helper.models import load_model_with_weights\n",
    "\n",
    "# Main Analysis Function\n",
    "from typing import Tuple\n",
    "from helper.global_variables import DEVICE, SUS_YAML_PATH, EXPERIMENT_YAML_PATH, TRAIN_YAML_PATH\n",
    "from helper.config import SuspiciousnessConfig, ExperimentConfig, TrainConfig\n",
    "from helper.models import get_layer, get_model\n",
    "from helper.datasets import get_dataset_loader\n",
    "from helper.suspiciousness import get_ochiai, get_tarantula\n",
    "from helper.suspiciousness import collect_activations, compute_hit_spectrum, log_diagnostics\n",
    "from helper.general import ensure_directory_exists, empty_gpu_cache\n",
    "from helper.suspiciousness import HitSpectrum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<helper.config.ExperimentRun object at 0x7fa49e521850>, <helper.config.ExperimentRun object at 0x7fa328876f90>, <helper.config.ExperimentRun object at 0x7fa49e5216d0>, <helper.config.ExperimentRun object at 0x7fa3287b26f0>, <helper.config.ExperimentRun object at 0x7fa3287b2c00>, <helper.config.ExperimentRun object at 0x7fa3287b3350>, <helper.config.ExperimentRun object at 0x7fa3287b3290>, <helper.config.ExperimentRun object at 0x7fa3287b3bf0>, <helper.config.ExperimentRun object at 0x7fa3287b2e40>, <helper.config.ExperimentRun object at 0x7fa3287b3a40>, <helper.config.ExperimentRun object at 0x7fa3287b3440>, <helper.config.ExperimentRun object at 0x7fa3287b30e0>, <helper.config.ExperimentRun object at 0x7fa3287b3740>, <helper.config.ExperimentRun object at 0x7fa3287b3620>, <helper.config.ExperimentRun object at 0x7fa3287b3260>, <helper.config.ExperimentRun object at 0x7fa3287b35f0>, <helper.config.ExperimentRun object at 0x7fa3287b3650>, <helper.config.ExperimentRun object at 0x7fa3287b3470>, <helper.config.ExperimentRun object at 0x7fa3287b3980>, <helper.config.ExperimentRun object at 0x7fa3287b38f0>, <helper.config.ExperimentRun object at 0x7fa3287b3560>, <helper.config.ExperimentRun object at 0x7fa3287b39b0>, <helper.config.ExperimentRun object at 0x7fa3287b3950>, <helper.config.ExperimentRun object at 0x7fa3287b3860>, <helper.config.ExperimentRun object at 0x7fa3287b3b30>, <helper.config.ExperimentRun object at 0x7fa3287b3920>, <helper.config.ExperimentRun object at 0x7fa3287b3830>, <helper.config.ExperimentRun object at 0x7fa3287b3c80>, <helper.config.ExperimentRun object at 0x7fa3287b3ad0>, <helper.config.ExperimentRun object at 0x7fa3287b3c20>, <helper.config.ExperimentRun object at 0x7fa3287b3a70>, <helper.config.ExperimentRun object at 0x7fa3287b3dd0>, <helper.config.ExperimentRun object at 0x7fa3287b3e90>, <helper.config.ExperimentRun object at 0x7fa3287b3d70>, <helper.config.ExperimentRun object at 0x7fa3287b3f20>, <helper.config.ExperimentRun object at 0x7fa3287b3e60>, <helper.config.ExperimentRun object at 0x7fa3287b3fb0>, <helper.config.ExperimentRun object at 0x7fa3287b3ec0>, <helper.config.ExperimentRun object at 0x7fa3287b3fe0>, <helper.config.ExperimentRun object at 0x7fa3287b3020>, <helper.config.ExperimentRun object at 0x7fa3287b3050>, <helper.config.ExperimentRun object at 0x7fa3287b2ea0>, <helper.config.ExperimentRun object at 0x7fa3286019d0>, <helper.config.ExperimentRun object at 0x7fa328600140>, <helper.config.ExperimentRun object at 0x7fa3286001d0>, <helper.config.ExperimentRun object at 0x7fa3286000b0>, <helper.config.ExperimentRun object at 0x7fa328600230>, <helper.config.ExperimentRun object at 0x7fa328600d40>, <helper.config.ExperimentRun object at 0x7fa328600470>, <helper.config.ExperimentRun object at 0x7fa3286003b0>, <helper.config.ExperimentRun object at 0x7fa3286004a0>, <helper.config.ExperimentRun object at 0x7fa3286003e0>, <helper.config.ExperimentRun object at 0x7fa3286005c0>, <helper.config.ExperimentRun object at 0x7fa328600440>, <helper.config.ExperimentRun object at 0x7fa3286002f0>, <helper.config.ExperimentRun object at 0x7fa328600710>, <helper.config.ExperimentRun object at 0x7fa3286005f0>, <helper.config.ExperimentRun object at 0x7fa3286006e0>]\n",
      "(\"Model layers of interest: [('fmnist-conv', 1), ('cifar10-mobilenet', 1), \"\n",
      " \"('mnist-dense8x20', 2), ('fmnist-dense', 1), ('cifar10-squeezenet', 3), \"\n",
      " \"('mnist-dense', 1), ('mnist-dense10x100', 2), ('cifar10-mobilenet', 3), \"\n",
      " \"('mnist-conv', 1), ('mnist-dense8x20', 1), ('cifar10-mobilenet', 2), \"\n",
      " \"('cifar10-squeezenet', 2), ('mnist-dense10x100', 1), ('cifar10-squeezenet', \"\n",
      " '1)]')\n"
     ]
    }
   ],
   "source": [
    "# Load Config\n",
    "train_config = TrainConfig(TRAIN_YAML_PATH)\n",
    "sus_config = SuspiciousnessConfig(SUS_YAML_PATH)\n",
    "exp_config = ExperimentConfig(EXPERIMENT_YAML_PATH, train_config)\n",
    "\n",
    "print(exp_config.exp_runs)\n",
    "# Parse Layer Config\n",
    "pprint(f\"Model layers of interest: {exp_config.get_relevant_model_layer_configs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Refactor this\n",
    "\n",
    "# Helper Functions\n",
    "def get_test_loader_wrapper(model_name: str) -> torch.utils.data.DataLoader:\n",
    "    # model match\n",
    "    if model_name.startswith(\"mnist-\"):\n",
    "        _, test_loader = get_dataset_loader(\"mnist\")\n",
    "    elif model_name.startswith(\"fmnist-\"):\n",
    "        _, test_loader = get_dataset_loader(\"fmnist\")\n",
    "    elif model_name.startswith(\"cifar10-\"):\n",
    "        _, test_loader = get_dataset_loader(\"cifar10\")\n",
    "    else:\n",
    "        raise Exception(f\"Unknown dataset: {model_name}\")\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit Spectrum Helper\n",
    "\n",
    "def unsqueeze_tensors(activations: torch.Tensor,\n",
    "                      targets: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    activations_copy = activations.clone()\n",
    "    targets_copy = targets.clone()\n",
    "    \n",
    "    # Handle shapes based on layer type\n",
    "    if len(activations.shape) == 4:  # Conv layer\n",
    "        # For conv layer, we want to analyze each feature map position\n",
    "        # Reshape activations to (batch_size, channels * height * width)\n",
    "        b, c, h, w = activations_copy.shape\n",
    "        activations_copy = activations_copy.view(b, c * h * w)\n",
    "        targets_copy = targets_copy.unsqueeze(1).expand(-1, c * h * w)\n",
    "    else:  # Dense layer\n",
    "        targets_copy = targets_copy.unsqueeze(1).expand(-1, activations_copy.shape[1])\n",
    "    \n",
    "    return activations_copy, targets_copy\n",
    "\n",
    "def hs_analysis(model, layer, test_loader, target_class=0):\n",
    "    \"\"\"\n",
    "    Analyze a specific layer of a model and compute hit spectrum.\n",
    "    \"\"\"\n",
    "    # Collect activations\n",
    "    activations, target_preds = collect_activations(model, layer, test_loader, target_class)\n",
    "\n",
    "    # Unsqueeze tensors\n",
    "    activations, target_preds = unsqueeze_tensors(activations, target_preds)\n",
    "    \n",
    "    # Compute hit spectrum\n",
    "    hs = compute_hit_spectrum(activations, target_preds, sus_config.activation_threshold)\n",
    "    \n",
    "    if sus_config.verbose:\n",
    "        log_diagnostics(activations, \n",
    "                        target_preds, \n",
    "                        activations > sus_config.activation_threshold, \n",
    "                        hs)\n",
    "    \n",
    "    return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Helpers\n",
    "\n",
    "@dataclass \n",
    "class SuspiciousnessResult:\n",
    "    ochiai: torch.Tensor\n",
    "    tarantula: torch.Tensor\n",
    "    duration: float\n",
    "\n",
    "def save_sus_values(sus_path: str, sus_results: SuspiciousnessResult):\n",
    "    dirname = os.path.dirname(sus_path)\n",
    "    ensure_directory_exists(dirname)\n",
    "    with open(sus_path, 'wb+') as file:\n",
    "            # process your file\n",
    "            sus = (sus_results.ochiai, sus_results.tarantula)\n",
    "            pickle.dump(sus, file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.rashedi/repositories/sus-adv-gen/helper/models.py:285: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(model_path)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DEVICE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown layer config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compute hit spectrum\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m hs \u001b[38;5;241m=\u001b[39m \u001b[43mhs_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_test_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msus_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_class\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Compute suspiciousness\u001b[39;00m\n\u001b[1;32m     40\u001b[0m ochiai_flattened \u001b[38;5;241m=\u001b[39m get_ochiai(hs)\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mhs_analysis\u001b[0;34m(model, layer, test_loader, target_class)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mAnalyze a specific layer of a model and compute hit spectrum.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Collect activations\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m activations, target_preds \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Unsqueeze tensors\u001b[39;00m\n\u001b[1;32m     28\u001b[0m activations, target_preds \u001b[38;5;241m=\u001b[39m unsqueeze_tensors(activations, target_preds)\n",
      "File \u001b[0;32m~/repositories/sus-adv-gen/helper/suspiciousness.py:37\u001b[0m, in \u001b[0;36mcollect_activations\u001b[0;34m(model, layer, loader, target_class)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m---> 37\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[43mDEVICE\u001b[49m), labels\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     38\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     39\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEVICE' is not defined"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "\n",
    "for model_name, layer_config in exp_config.get_relevant_model_layer_configs():\n",
    "\n",
    "    # Load model\n",
    "    model = load_model_with_weights(train_config.look_up_path(model_name))\n",
    "    \n",
    "    # Start timer\n",
    "    time_pre = time.perf_counter()\n",
    "    \n",
    "    # Get test dataset loader\n",
    "    test_loader = get_test_loader_wrapper(model_name)\n",
    "    \n",
    "    # Get Sub Dataset\n",
    "    test_dataset = test_loader.dataset\n",
    "    \n",
    "    if len(test_dataset) > sus_config.samples:\n",
    "        sub_test_dataset = Subset(test_dataset, range(sus_config.samples))\n",
    "    else:\n",
    "        raise Exception(\"Desired dataset does not have enough samples.\")\n",
    "\n",
    "    # Shuffle enabled\n",
    "    sub_test_loader = torch.utils.data.DataLoader(sub_test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    layer_func = get_layer(model_name, layer_config)\n",
    "    layer = layer_func(model)\n",
    "    \n",
    "    if layer is None:\n",
    "        raise Exception(\"Unknown layer config\")\n",
    "    \n",
    "    # Compute hit spectrum\n",
    "    hs = hs_analysis(\n",
    "        model=model,\n",
    "        layer=layer,\n",
    "        test_loader=sub_test_loader,\n",
    "        target_class=sus_config.target_class\n",
    "    )\n",
    "\n",
    "    # Compute suspiciousness\n",
    "    ochiai_flattened = get_ochiai(hs)\n",
    "    ochiai = ochiai_flattened.reshape(hs.layer_shape)\n",
    "\n",
    "    tarantula_flattend = get_tarantula(hs)\n",
    "    tarantula = tarantula_flattend.reshape(hs.layer_shape)\n",
    "    \n",
    "    # End timer\n",
    "    time_diff = time.perf_counter() - time_pre\n",
    "    \n",
    "    # Store results\n",
    "    sus_result = SuspiciousnessResult(ochiai, tarantula, time_diff)\n",
    "    times.append(sus_result)\n",
    "    \n",
    "    # Save results\n",
    "    sus_path = sus_config.target_dir + f\"{model_name}/\" + f\"layer-config-{layer_config}.pickle\"\n",
    "    save_sus_values(sus_path, \n",
    "                    sus_result)\n",
    "\n",
    "    empty_gpu_cache()\n",
    "    \n",
    "# Stored Times\n",
    "df = pd.DataFrame(times)\n",
    "if df.empty:\n",
    "    raise ValueError(\"No valid results to save\")\n",
    "    \n",
    "df = df.sort_values(['model_name', 'layer_config'])\n",
    "\n",
    "ensure_directory_exists(\"results-adv-gen\")\n",
    "df.to_csv(os.path.join(\"results-adv-gen\", 'sus-comp-times.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
