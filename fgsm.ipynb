{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from helper.datasets import get_dataset_loader\n",
    "from helper.general import empty_gpu_cache\n",
    "from helper.models import evaluate_model, get_model\n",
    "from helper.config import TrainConfig\n",
    "from helper.global_variables import DEVICE, TRAIN_YAML_PATH\n",
    "\n",
    "samples_range = range(1000)\n",
    "\n",
    "def fgsm_attack(model, loss_fn, dataset_loader, epsilon):\n",
    "    modified_images = []\n",
    "    labels_buffer = []\n",
    "    model.eval()\n",
    "    \n",
    "    for images, labels in tqdm(dataset_loader, \"FGSM Attack\"):\n",
    "        images = images.to(DEVICE)\n",
    "        images_altered = images.clone()\n",
    "        labels = labels.to(DEVICE)\n",
    "        images.requires_grad_()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = images.grad.data\n",
    "        images_altered = images + epsilon * data_grad.sign()\n",
    "        images_altered = torch.clamp(images_altered, 0, 1)\n",
    "        \n",
    "        labels_buffer.append(labels)\n",
    "        modified_images.append(images_altered)\n",
    "        empty_gpu_cache()\n",
    "    return torch.cat(modified_images), torch.cat(labels_buffer)\n",
    "\n",
    "train_config = TrainConfig(TRAIN_YAML_PATH)\n",
    "print(train_config.models)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for model_name, model_path in train_config.models:\n",
    "    model = get_model(model_name)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    # Get data and evaluate\n",
    "    # \n",
    "    _, test_loader = get_dataset_loader(model_name.split(\"-\")[0], 32)\n",
    "    subset = torch.utils.data.Subset(\n",
    "        test_loader.dataset,\n",
    "        samples_range  # Take first 2500 samples\n",
    "    )\n",
    "    subset_loader = DataLoader(subset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    empty_gpu_cache()\n",
    "    accuracy_before = evaluate_model(model, subset_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    print(f\"accuracy of {model_name} (before): {accuracy_before:.4f}\")\n",
    "    \n",
    "    \n",
    "    time_pre = time.perf_counter()\n",
    "    epsilon = 0.1\n",
    "    try: \n",
    "        perturbed_images, labels = fgsm_attack(model, \n",
    "                                    loss_fn, \n",
    "                                    subset_loader, \n",
    "                                    epsilon)\n",
    "    except:\n",
    "        print(\"Error in fgsm_attack\")\n",
    "    time_post = time.perf_counter() - time_pre\n",
    "    print(f\"FGSM time: {time_post:.2f} s\")\n",
    "    \n",
    "    perturbed_dataset = torch.utils.data.TensorDataset(perturbed_images, labels)\n",
    "    \n",
    "    # Batch Size should be obtained from single place\n",
    "    perturbed_loader = DataLoader(perturbed_dataset, batch_size=64, shuffle=False)\n",
    "    accuracy_before = evaluate_model(model, perturbed_loader)\n",
    "\n",
    "    empty_gpu_cache()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
